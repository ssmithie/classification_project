{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I import *all* of the libraries I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, auc, classification_report, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bk_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['BOROUGH','NEIGHBORHOOD','BUILDING_CLASS_CATEGORY',\n",
    "       'TAX_CLASS_AT_PRESENT', 'BLOCK', 'LOT', 'BUILDING_CLASS_AT_PRESENT',\n",
    "       'ADDRESS', 'RESIDENTIAL_UNITS',\n",
    "       'COMMERCIAL_UNITS', 'TOTAL_UNITS', 'YEAR_BUILT', \n",
    "       'BUILDING_CLASS_AT_TIME_OF_SALE', 'SALE_PRICE', 'SALE_DATE',\n",
    "       'zip_mean', 'above_mean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable\n",
      "above_bk_mean\n",
      "0    12252\n",
      "1     3178\n",
      "Name: above_bk_mean, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Target Variable')\n",
    "print(df.groupby(['above_bk_mean']).above_bk_mean.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my model:\n",
    "\n",
    "0 = below the mean,\n",
    "1 = above the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think for my model, if I'm someone that's looking at investing I would want to wrongly guess that it's above the mean (false positive = Type I error), because I would not want to wrongly buy a house thinking it was below the mean.\n",
    "Be better at predicting the negatives!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['SALE_SEASON','ZIP_CODE', 'APARTMENT_NUMBER', 'TAX_CLASS_AT_TIME_OF_SALE', 'year'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of features\n",
    "X = df.drop('above_bk_mean', axis = 1) # grabs everything else but target\n",
    "\n",
    "# Create target variable\n",
    "y = df['above_bk_mean'] # y is the column we're trying to predict\n",
    "\n",
    "# Create a list of the features being used in the \n",
    "feature_cols = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to train test split my data 75/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics used to evaluate my model:\n",
    "\n",
    "**Classification Accuracy:** Overall, how often is the classifier correct?\n",
    "\n",
    "I should check this against the null accuracy - how often it would be right if it always guessed yes.\n",
    "\n",
    "**Precision**: When a positive value is predicted, how often is the prediction correct? i.e When it predicts that it is above the mean, how often is this correct?\n",
    "\n",
    "**Recall(sensitivity)**: What proportion of the actual positives were identified correctly\n",
    "- How \"sensitive\" is the classifier to detecting positive instances?\n",
    "- Also known as \"True Positive Rate\" or \"Recall\"\n",
    "\n",
    "**Specificity**: When the actual value is negative, how often is the prediction correct? When it *is* below the mean, how often is it right - I think this is what I want to maximize.\n",
    "\n",
    "How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n",
    "\n",
    "**False Positive Rate:** When the actual value is negative, how often is the prediction incorrect? - I want this to be low!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
